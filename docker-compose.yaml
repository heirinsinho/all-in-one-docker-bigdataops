services:
  spark-master:
    container_name: spark-master
    image: base-spark:latest
    entrypoint: [ './entrypoint.sh', 'master' ]
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    env_file:
      - ./spark/.env
    ports:
      - 8080:8080
      - 7077:7077

  spark-history-server:
    container_name: spark-history-server
    image: base-spark:latest
    restart: always
    entrypoint: [ './entrypoint.sh', 'history' ]
    depends_on:
      - spark-master
    env_file:
      - ./spark/.env
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    ports:
      - 18080:18080

  spark-worker:
    image: base-spark:latest
    entrypoint: [ './entrypoint.sh', 'worker' ]
    depends_on:
      - spark-master
    env_file:
      - spark/.env
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf


  namenode:
    platform: linux/amd64
    build: ./hadoop/namenode
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - ./hadoop/namenode/data:/hadoop/dfs/name
      - ./hadoop/applications:/hadoop/applications
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop/.env

  datanode1:
    platform: linux/amd64
    build: ./hadoop/datanode
    container_name: datanode1
    restart: always
    volumes:
      - ./hadoop/datanode/data/datanode1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop/.env

  datanode2:
    platform: linux/amd64
    build: ./hadoop/datanode
    container_name: datanode2
    restart: always
    volumes:
      - ./hadoop/datanode/data/datanode2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop/.env

  resourcemanager:
    platform: linux/amd64
    build: ./hadoop/resourcemanager
    container_name: yarn
    ports:
      - 8088:8088
    restart: always
    depends_on:
      - namenode
      - datanode1
      - datanode2
    environment:
      SERVICE_PRECONDITION: 'namenode:9870 datanode1:9864 datanode2:9864'
    env_file:
      - ./hadoop/.env

  nodemanager:
    platform: linux/amd64
    build: ./hadoop/nodemanager
    container_name: nodemanager
    ports:
      - 8042:8042
    restart: always
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
    environment:
      SERVICE_PRECONDITION: 'namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088'
    env_file:
      - ./hadoop/.env

  historyserver:
    platform: linux/amd64
    build: ./hadoop/historyserver
    container_name: historyserver
    ports:
      - 8188:8188
    restart: always
    volumes:
      - ./hadoop/historyserver/data:/hadoop/yarn/timeline
    depends_on:
      - namenode
      - datanode1
      - datanode2
    environment:
      SERVICE_PRECONDITION: 'namenode:9870 datanode1:9864 datanode2:9864'
    env_file:
      - ./hadoop/.env

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - 2181:2181

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    restart: always
    ports:
      - 9092:9092
      - 9094:9094
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

  airflow:
    platform: linux/amd64
    container_name: airflow
    image: base-airflow:latest
    entrypoint: /bin/bash
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres:5432/airflow_db
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    command:
      - -c
      - airflow db init &&
        airflow users create --role Admin --username admin --password admin --email admin@airflow.com --firstname admin --lastname admin &&
        airflow standalone
    ports:
      - 8090:8080
    volumes:
      - ./airflow/data:/opt/airflow/data
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
      - .env.madflow:/opt/airflow/dags/.env


  jupyter:
    platform: linux/amd64
    image: base-jupyter:latest
    container_name: jupyter
    ports:
      - 8888:8888
      - 4040:4040
    environment:
      - JUPYTER_ENABLE_LAB=yes
    depends_on:
      - spark-master
    volumes:
      - ./jupyter/notebooks:/home/jovyan/notebooks
      - ./jupyter/data:/home/jovyan/data
      - .env.madflow:/home/jovyan/notebooks/madflow/.env

  postgres:
    image: postgres:16
    restart: unless-stopped
    container_name: postgres
    environment:
      POSTGRES_DB: 'postgres'
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: 'postgres'
    ports:
      - '5432:5432'
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - ./postgres/init-db:/docker-entrypoint-initdb.d

  metastore:
    image: apache/hive:4.0.0
    depends_on:
      - postgres
    restart: unless-stopped
    container_name: metastore
    environment:
      DB_DRIVER: postgres
      VERBOSE: "true"
      SERVICE_NAME: 'metastore'
    ports:
      - '9083:9083'
    volumes:
      - ./hive/warehouse:/opt/hive/data/warehouse
      - ./hive/postgresql-42.7.4.jar:/opt/hive/lib/postgres.jar
      - ./hive/hive-site.xml:/opt/hive/conf/hive-site.xml

  hiveserver2:
    image: apache/hive:4.0.0
    depends_on:
      - metastore
    restart: unless-stopped
    container_name: hiveserver2
    environment:
      SERVICE_OPTS: "-Dhive:metastore:uris=thrift://metastore:9083"
      VERBOSE: "true"
      SERVICE_NAME: 'hiveserver2'
    ports:
      - '10000:10000'
      - '10002:10002'
    volumes:
      - ./hive/warehouse:/opt/hive/data/warehouse

  hue:
    platform: linux/amd64
    container_name: hue
    image: gethue/hue:latest
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088 metastore:9083 postgres:5432"
    ports:
      - "9999:8888"
    volumes:
      - ./hue/hue.ini:/usr/share/hue/desktop/conf/hue-overrides.ini
    depends_on:
      - postgres
