{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd6f56d-b27d-4a7f-a8b0-357b54e10354",
   "metadata": {},
   "source": [
    "### Worst use of Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635856e-dde1-43eb-9935-ccf2c0ec0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/31 17:18:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b0a315f65ea6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Worst use of Window Function</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f39b80cf590>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Worst use of Window Function\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9a9925-27c6-426d-9764-5be7c7c23ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15271b5d-0825-420f-9080-f76362e02120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Spark default config\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122fe091-8da7-4633-b998-26fc9532847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read example data set\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "df = spark.read.parquet(\"hdfs://namenode:9000/input/data/sales.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4738247-e68b-44c7-88a6-f091df957d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan ExistingRDD[transacted_at#0,trx_id#1L,retailer_id#2L,description#3,amount#4,city_id#5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76329992-99a6-483e-ba22-4ca4d168b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|partition_id|  count|\n",
      "+------------+-------+\n",
      "|           6|  53999|\n",
      "|           3|1048576|\n",
      "+------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"partition_id\", F.spark_partition_id()).groupBy(\n",
    "    \"partition_id\"\n",
    ").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2ed3b6-5d78-4d89-aa3c-ef9be55e8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/26 13:16:07 WARN TaskSetManager: Stage 3 contains a task of very large size (8828 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+--------------------+-------+------------+\n",
      "|       transacted_at|    trx_id|retailer_id|         description| amount|     city_id|\n",
      "+--------------------+----------+-----------+--------------------+-------+------------+\n",
      "|2017-11-24T19:00:...|1995601912| 2077350195|Walgreen       11-25| 197.23|2.16510448E8|\n",
      "|2017-11-24T19:00:...|1734117021|  644879053|unkn    ppd id: 7...|   8.58|  9.302599E8|\n",
      "|2017-11-24T19:00:...|1734117022|  847200066|Wal-Mart  ppd id:...|1737.26|1.64641549E9|\n",
      "|2017-11-24T19:00:...|1734117030| 1953761884|Home Depot     pp...|  384.5|2.87177632E8|\n",
      "|2017-11-24T19:00:...|1734117089| 1898522855| Target        11-25|  66.33| 1.8555305E9|\n",
      "|2017-11-24T19:00:...|1734117117|  997626433|Sears  ppd id: 85...| 298.87| 9.5734701E8|\n",
      "|2017-11-24T19:00:...|1734117123| 1953761884|unkn   ppd id: 15...|  19.55| 4.5522088E7|\n",
      "|2017-11-24T19:00:...|1734117152| 1429095612|Ikea     arc id: ...|   9.39|1.26854131E9|\n",
      "|2017-11-24T19:00:...|1734117153|  847200066|unkn        Kings...|2907.57|1.48393114E9|\n",
      "|2017-11-24T19:00:...|1734117212| 1996661856|unkn    ppd id: 4...| 140.38|3.36763936E8|\n",
      "|2017-11-24T19:00:...|1734117241|  486576507|              iTunes|2912.67|1.66387302E9|\n",
      "|2017-11-24T19:00:...|2076947148|  847200066|Wal-Mart         ...|  62.83|1.55660083E9|\n",
      "|2017-11-24T19:00:...|2076947147|  562903918|McDonald's    ccd...|  31.37|  9.302599E8|\n",
      "|2017-11-24T19:00:...|2076947146|  511877722|unkn     ccd id: ...|1915.35| 1.6987625E9|\n",
      "|2017-11-24T19:00:...|2076947113| 1996661856|AutoZone  arc id:...| 1523.6|1.75961216E9|\n",
      "|2017-11-24T19:00:...|2076947018|  902350112|DineEquity    arc...|  22.28|2.13065754E9|\n",
      "|2017-11-24T19:00:...|2076946994| 1898522855|Target    ppd id:...|2589.93| 2.0740055E9|\n",
      "|2017-11-24T19:00:...|2076946985|  847200066|Wal-Mart    ppd i...|   42.2|4.59344512E8|\n",
      "|2017-11-24T19:00:...|2076946960|  386167994|Wendy's  ppd id: ...|  14.62|3.52952448E8|\n",
      "|2017-11-24T19:00:...|2076946954|  486576507|iTunes     ppd id...|  37.42|4.85114752E8|\n",
      "+--------------------+----------+-----------+--------------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0ac5b0-ad82-4850-b461-3bcd399dcca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005cf23a-3d1f-41d0-8ccb-bf523b8888fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/31 17:23:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:23:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:23:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:23:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:23:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use row_number() to generate ids\n",
    "df_with_row_num = df.withColumn(\"_id\", F.expr(\"row_number() over (order by null)\"))\n",
    "\n",
    "# Write the dataset in noop for performance benchmarking\n",
    "df_with_row_num.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f50ad-c20d-4fea-bafb-ca141977aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_row_num.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7dfa359-4aa5-4126-9f97-8a0088475968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/31 17:24:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:24:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:24:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:24:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/10/31 17:24:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the number of partitions\n",
    "df_with_row_num.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4380ed-8b22-4d95-887f-d9fdf3b8b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use Spark in-built monotonically_increasing_id to generate ids\n",
    "df_with_incr_id = df.withColumn(\"_id\", F.monotonically_increasing_id())\n",
    "\n",
    "# Write the dataset in noop for performance benchmarking\n",
    "df_with_incr_id.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec64262-ef48-4937-be32-0a49f33114e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_incr_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfae94f-c1a4-420e-9517-cfb90eb92782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the number of partitions\n",
    "df_with_incr_id.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d39b7d-dfc8-4286-b1d2-c6065c51a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf0ecf-a1b4-470e-b672-466167169867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
