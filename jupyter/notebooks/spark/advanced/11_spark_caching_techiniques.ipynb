{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bf5b8-f3f4-4877-a002-42667addfbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/11 16:12:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://62964de4bd00:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Understand Caching</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f76b4157090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Understand Caching\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.memory\", \"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad8280-2561-4b8e-a1ad-22d68c1fb971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .load(\"hdfs://namenode:9000/input/data/employee_records.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affa9a57-b5d0-4103-aba6-c3b7dd681d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+--------------------+--------------------+------+-------------+\n",
      "|first_name| last_name|           job_title|       dob|               email|               phone|salary|department_id|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+------+-------------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|       (699)525-4827|512653|            8|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|  (750)846-1602x7458|999836|            7|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24| jturner@example.net|    873.820.0518x825|131900|           10|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16|  erik33@example.net|    820-813-0557x624|485506|            1|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|       (705)900-5337|604738|            8|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16|patrickalexandra@...|        211.440.5466|483339|            6|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28|  lori44@example.net|        936-403-3179|419644|            7|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01| ygordon@example.org|       (889)246-5588|205939|            7|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16| diana44@example.net|001-647-530-5036x...|671167|            8|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28|  ryan36@example.com|   422.562.7254x3159|993829|            7|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11|monica93@example.org|+1-535-652-9715x6...|702101|            4|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01|stephanie65@examp...|   (652)815-7973x298|570960|            6|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17|pwilliams@example...|001-245-848-0028x...|339441|            6|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18|gabrielmurray@exa...|          9247590563|469728|            8|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13|nicholas76@exampl...|   311.439.1606x3342|582291|            4|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07|  mark07@example.com|    001-912-206-6456|146456|            4|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02|griffinmary@examp...| +1-791-344-7586x548|544732|            1|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12|alexandraobrien@e...|        216.696.6061|399503|            3|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10|  rmorse@example.org|  (726)363-7526x9965|761988|           10|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02|brandoncardenas@e...| (964)451-9007x22496|660659|            4|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a243560-b1c9-470c-a55e-43b89d2c8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache DataFrame (cache or persist)\n",
    "\n",
    "df_cache = df.where(\"salary > 100000\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f256-5026-4b0b-b3df-2d9fd8cc462d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]\r"
     ]
    }
   ],
   "source": [
    "df_cache.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425d67b-9cf6-482f-9b9f-3b92262dda7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.where(\"salary > 5000\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0cea16-98b0-4d89-b665-6895ca351e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\"salary > 500000\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372bba7-632e-410d-be3b-7d9d729586c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cache.where(\"salary > 500000\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b44adb-9c11-4029-b86d-04b6f395c967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MEMORY_ONLY, MEMORY_AND_DISK, MEMORY_ONLY_SER, MEMORY_AND_DISK_SER, DISK_ONLY, MEMORY_ONLY_2, MEMORY_AND_DISK_2\n",
    "import pyspark\n",
    "\n",
    "df_persist = df.persist(pyspark.StorageLevel.MEMORY_ONLY_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5009af8-74c1-450d-ae7f-36e8ae64ef1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_persist.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704050a-93ef-464f-b790-5b82aba08a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cache\n",
    "\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df09022-e1f3-4bdf-a27b-26500995c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|    Smith|21740|\n",
      "|  Johnson|16928|\n",
      "| Williams|13943|\n",
      "|    Jones|12511|\n",
      "|    Brown|12444|\n",
      "|   Miller|10248|\n",
      "|    Davis| 9865|\n",
      "|   Garcia| 7654|\n",
      "|Rodriguez| 7335|\n",
      "| Martinez| 7052|\n",
      "|   Wilson| 6993|\n",
      "| Anderson| 6886|\n",
      "|   Taylor| 6667|\n",
      "|   Thomas| 6452|\n",
      "|    Moore| 6393|\n",
      "|Hernandez| 6363|\n",
      "|   Martin| 6130|\n",
      "|  Jackson| 6044|\n",
      "|    White| 5850|\n",
      "| Thompson| 5836|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "emp = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .load(\"hdfs://namenode:9000/input/data/employee_records.csv\")\n",
    ")\n",
    "\n",
    "emp.groupby(\"last_name\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025bb5d-f522-490c-bf4f-8058cd35d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The real use of caching\n",
    "# Image a costly operation: join two big df\n",
    "# and the result of the join is going to be used for later analytics\n",
    "# in this case, if you cache the join result, you never run the full dag again\n",
    "\n",
    "# we are going to get possible siblings in department 1\n",
    "\n",
    "df1 = emp.filter(F.col(\"department_id\") == 1).select(\n",
    "    *(F.col(x).alias(x + \"_1\") for x in emp.columns)\n",
    ")\n",
    "df2 = emp.filter(F.col(\"department_id\") == 1).select(\n",
    "    *(F.col(x).alias(x + \"_2\") for x in emp.columns)\n",
    ")\n",
    "\n",
    "siblings = df1.join(df2, on=df1.last_name_1 == df2.last_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187a9353-963b-49ca-816b-98cb814c3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name_1: string (nullable = true)\n",
      " |-- last_name_1: string (nullable = true)\n",
      " |-- job_title_1: string (nullable = true)\n",
      " |-- dob_1: date (nullable = true)\n",
      " |-- email_1: string (nullable = true)\n",
      " |-- phone_1: string (nullable = true)\n",
      " |-- salary_1: integer (nullable = true)\n",
      " |-- department_id_1: integer (nullable = true)\n",
      " |-- first_name_2: string (nullable = true)\n",
      " |-- last_name_2: string (nullable = true)\n",
      " |-- job_title_2: string (nullable = true)\n",
      " |-- dob_2: date (nullable = true)\n",
      " |-- email_2: string (nullable = true)\n",
      " |-- phone_2: string (nullable = true)\n",
      " |-- salary_2: integer (nullable = true)\n",
      " |-- department_id_2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "siblings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255f67e-c806-4505-a4d0-26fba889d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE DUPLICATED AND UNLIKELY\n",
    "siblings = siblings.filter(F.col(\"email_1\") != F.col(\"email_2\"))\n",
    "siblings = siblings.filter(\n",
    "    F.abs(F.months_between(F.col(\"dob_1\"), F.col(\"dob_2\"))) < 120\n",
    ")\n",
    "siblings = siblings.filter(\n",
    "    F.concat(F.col(\"email_1\"), F.lit(\"-\"), F.col(\"email_2\"))\n",
    "    != F.concat(F.col(\"email_2\"), F.lit(\"-\"), F.col(\"email_1\"))\n",
    ")\n",
    "\n",
    "# GROUP BY TITLE PAIRS\n",
    "siblings = siblings.withColumn(\n",
    "    \"pair_title_1\", F.least(\"job_title_1\", \"job_title_2\")\n",
    ").withColumn(\"pair_title_2\", F.greatest(\"job_title_1\", \"job_title_2\"))\n",
    "siblings_grouped = siblings.groupby(\"pair_title_1\", \"pair_title_2\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded6d500-61ee-4deb-9cf7-6f5e0b0d6824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|        pair_title_1|        pair_title_2|count|\n",
      "+--------------------+--------------------+-----+\n",
      "| Colour technologist|Engineer, electrical|   56|\n",
      "|         Chiropodist|Sound technician,...|  100|\n",
      "| Designer, furniture|Production design...|   74|\n",
      "|Environmental con...|   Recycling officer|   96|\n",
      "|Claims inspector/...|Financial risk an...|  100|\n",
      "|Clinical cytogene...|Designer, televis...|   66|\n",
      "|Biochemist, clinical|        Neurosurgeon|   80|\n",
      "|Financial risk an...|Radio broadcast a...|  106|\n",
      "|Commercial hortic...|Speech and langua...|   58|\n",
      "|Community arts wo...|Television/film/v...|   58|\n",
      "|Amenity horticult...|Production assist...|  100|\n",
      "|Amenity horticult...|            Musician|   46|\n",
      "|   Company secretary|Journalist, newsp...|   84|\n",
      "|Education officer...|Production design...|   66|\n",
      "|Higher education ...|Museum/gallery co...|  100|\n",
      "|          Oncologist|    Public librarian|   98|\n",
      "|Insurance underwr...|          Oncologist|  104|\n",
      "|Insurance claims ...|Teacher, special ...|   60|\n",
      "|    Fashion designer|Horticulturist, a...|   78|\n",
      "|Fitness centre ma...|Licensed conveyancer|   46|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "siblings_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610049e2-e581-4423-9cb0-72d619d4e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|       214|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|     22478|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:==================================>                       (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|   2454176|\n",
      "+----------+\n",
      "\n",
      "33.853596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# WITHOUT CACHING\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Total of possible siblings\n",
    "print(siblings_grouped.count())\n",
    "\n",
    "# Total of siblings who are Oncologist or H. Manager\n",
    "siblings_grouped.filter(\n",
    "    F.col(\"pair_title_1\").isin(\"Oncologist\", \"Hotel manager\")\n",
    "    & F.col(\"pair_title_2\").isin(\"Oncologist\", \"Hotel manager\")\n",
    ").select(F.sum(F.col(\"count\"))).show()\n",
    "\n",
    "# Total of siblings with same role\n",
    "siblings_grouped.filter(F.col(\"pair_title_1\") == F.col(\"pair_title_2\")).select(\n",
    "    F.sum(F.col(\"count\"))\n",
    ").show()\n",
    "\n",
    "# Total of siblings starting with A\n",
    "siblings_grouped.filter(F.substring(F.col(\"pair_title_1\"), 1, 1) == F.lit(\"A\")).select(\n",
    "    F.sum(F.col(\"count\"))\n",
    ").show()\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "print((end - start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6409f28-b007-46a1-bac6-3ad61a5bb632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|       214|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|     22478|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|   2454176|\n",
      "+----------+\n",
      "\n",
      "22.623305\n"
     ]
    }
   ],
   "source": [
    "# WITH CACHING\n",
    "\n",
    "siblings_grouped.cache()\n",
    "\n",
    "start = datetime.now()\n",
    "print(siblings_grouped.count())\n",
    "siblings_grouped.filter(\n",
    "    F.col(\"pair_title_1\").isin(\"Oncologist\", \"Hotel manager\")\n",
    "    & F.col(\"pair_title_2\").isin(\"Oncologist\", \"Hotel manager\")\n",
    ").select(F.sum(F.col(\"count\"))).show()\n",
    "siblings_grouped.filter(F.col(\"pair_title_1\") == F.col(\"pair_title_2\")).select(\n",
    "    F.sum(F.col(\"count\"))\n",
    ").show()\n",
    "siblings_grouped.filter(F.substring(F.col(\"pair_title_1\"), 1, 1) == F.lit(\"A\")).select(\n",
    "    F.sum(F.col(\"count\"))\n",
    ").show()\n",
    "end = datetime.now()\n",
    "\n",
    "print((end - start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99c98b6-ab4a-45cd-bbb8-5fc7e461ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"hdfs://namenode:9000/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6663f6f0-7ed0-4705-b8c5-eb3a53f54d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "siblings_grouped_checkpoint = siblings_grouped.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592c56f6-a1aa-4004-bf64-02a748835c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204480"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siblings_grouped_checkpoint.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb76289-67ae-4ca0-bf97-65a71f1843c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86115c8-110e-41a4-a178-6c965846a9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
