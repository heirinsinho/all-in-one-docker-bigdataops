{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3634350c-aefe-44a7-98bb-6f3852394d16",
   "metadata": {},
   "source": [
    "# Flatten JSON data dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f85317-0944-43ac-a6d6-1a454b098662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/21 15:48:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a5828d5b0f00:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Flatten JSON data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff02016ba90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Flatten JSON data\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1df0e8-7047-41f4-bf1e-ca609213dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------+\n",
      "|emp_no|emp_details                                                          |\n",
      "+------+---------------------------------------------------------------------+\n",
      "|EMP001|{account, Ramesh, null, Singh, [excel, tally, word]}                 |\n",
      "|EMP002|{sales, Siv, null, Kumar, [biking, sales]}                           |\n",
      "|EMP003|{hr, MS Raghvan, {basic, expert}, null, [communication, soft-skills]}|\n",
      "+------+---------------------------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- emp_no: string (nullable = true)\n",
      " |-- emp_details: struct (nullable = true)\n",
      " |    |-- dept: string (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- hobbies: struct (nullable = true)\n",
      " |    |    |-- computers: string (nullable = true)\n",
      " |    |    |-- cycling: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |    |-- skills: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets create an Example Data Frame to hold JSON data\n",
    "\n",
    "# Example Data Frame with column having JSON data\n",
    "_data = [\n",
    "    [\n",
    "        \"EMP001\",\n",
    "        '{\"dept\" : \"account\", \"fname\": \"Ramesh\", \"lname\": \"Singh\", \"skills\": [\"excel\", \"tally\", \"word\"]}',\n",
    "    ],\n",
    "    [\n",
    "        \"EMP002\",\n",
    "        '{\"dept\" : \"sales\", \"fname\": \"Siv\", \"lname\": \"Kumar\", \"skills\": [\"biking\", \"sales\"]}',\n",
    "    ],\n",
    "    [\n",
    "        \"EMP003\",\n",
    "        '{\"dept\" : \"hr\", \"fname\": \"MS Raghvan\", \"skills\": [\"communication\", \"soft-skills\"], \"hobbies\" : {\"cycling\": \"expert\", \"computers\":\"basic\"}}',\n",
    "    ],\n",
    "]\n",
    "\n",
    "# Columns for the data\n",
    "_cols = [\"emp_no\", \"raw_data\"]\n",
    "\n",
    "# Lets create the raw Data Frame\n",
    "df_raw = spark.createDataFrame(data=_data, schema=_cols)\n",
    "\n",
    "# Determine the schema of the JSON payload from the column\n",
    "json_schema_df = spark.read.json(df_raw.rdd.map(lambda row: row.raw_data))\n",
    "json_schema = json_schema_df.schema\n",
    "\n",
    "# Apply the schema to payload to read the data\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "df_details = df_raw.withColumn(\n",
    "    \"emp_details\", from_json(df_raw[\"raw_data\"], json_schema)\n",
    ").drop(\"raw_data\")\n",
    "df_details.show(10, False)\n",
    "df_details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9fe16-f0b5-419d-b1a9-c3f315eb926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function to flatten the data dynamically\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "# Create outer method to return the flattened Data Frame\n",
    "def flatten_json_df(_df: DataFrame) -> DataFrame:\n",
    "    # List to hold the dynamically generated column names\n",
    "    flattened_col_list = []\n",
    "\n",
    "    # Inner method to iterate over Data Frame to generate the column list\n",
    "    def get_flattened_cols(df: DataFrame, struct_col: str = None) -> None:\n",
    "        for col in df.columns:\n",
    "            if df.schema[col].dataType.typeName() != \"struct\":\n",
    "                if struct_col is None:\n",
    "                    flattened_col_list.append(f\"{col} as {col.replace('.', '_')}\")\n",
    "                else:\n",
    "                    t = struct_col + \".\" + col\n",
    "                    flattened_col_list.append(f\"{t} as {t.replace('.', '_')}\")\n",
    "            else:\n",
    "                chained_col = struct_col + \".\" + col if struct_col is not None else col\n",
    "                get_flattened_cols(df.select(col + \".*\"), chained_col)\n",
    "\n",
    "    # Call the inner Method\n",
    "    get_flattened_cols(_df)\n",
    "\n",
    "    # Return the flattened Data Frame\n",
    "    return _df.selectExpr(flattened_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8022cc39-04ec-4266-9a48-0fed056759aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
      "|emp_no|emp_details_dept|emp_details_fname|emp_details_hobbies_computers|emp_details_hobbies_cycling|emp_details_lname|  emp_details_skills|\n",
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
      "|EMP001|         account|           Ramesh|                         null|                       null|            Singh|[excel, tally, word]|\n",
      "|EMP002|           sales|              Siv|                         null|                       null|            Kumar|     [biking, sales]|\n",
      "|EMP003|              hr|       MS Raghvan|                        basic|                     expert|             null|[communication, s...|\n",
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- emp_no: string (nullable = true)\n",
      " |-- emp_details_dept: string (nullable = true)\n",
      " |-- emp_details_fname: string (nullable = true)\n",
      " |-- emp_details_hobbies_computers: string (nullable = true)\n",
      " |-- emp_details_hobbies_cycling: string (nullable = true)\n",
      " |-- emp_details_lname: string (nullable = true)\n",
      " |-- emp_details_skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the flattened DF\n",
    "flattened_df = flatten_json_df(df_details)\n",
    "flattened_df.show(10)\n",
    "\n",
    "# Print Schema\n",
    "flattened_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771cf5d-31bd-4186-935f-c3bd87e07897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+-------------+\n",
      "|emp_no|emp_details_dept|emp_details_fname|emp_details_hobbies_computers|emp_details_hobbies_cycling|emp_details_lname|       skills|\n",
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+-------------+\n",
      "|EMP001|         account|           Ramesh|                         null|                       null|            Singh|        excel|\n",
      "|EMP001|         account|           Ramesh|                         null|                       null|            Singh|        tally|\n",
      "|EMP001|         account|           Ramesh|                         null|                       null|            Singh|         word|\n",
      "|EMP002|           sales|              Siv|                         null|                       null|            Kumar|       biking|\n",
      "|EMP002|           sales|              Siv|                         null|                       null|            Kumar|        sales|\n",
      "|EMP003|              hr|       MS Raghvan|                        basic|                     expert|             null|communication|\n",
      "|EMP003|              hr|       MS Raghvan|                        basic|                     expert|             null|  soft-skills|\n",
      "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case we now want to explode the Array/List field - emp_details_skills\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "flattened_df.withColumn(\"skills\", explode(\"emp_details_skills\")).drop(\n",
    "    \"emp_details_skills\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9dae9f7-a04a-4952-b5a3-ecd27b1b979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1f2e8-8859-4d94-92c8-dda1d36eb575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
