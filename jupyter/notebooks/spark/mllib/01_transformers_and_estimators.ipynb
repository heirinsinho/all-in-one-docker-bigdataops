{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578e136-fd92-4316-9e57-4fe75f6207b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Spark MLlib\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966f739-ab3e-4ee0-932f-0ec2cefc163d",
   "metadata": {},
   "source": [
    "# TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42909566-2514-41dc-99fc-e570eb30af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Creaci√≥n de un nuevo DataFrame con nombres de columnas y vectores diferentes.\n",
    "dataset = spark.createDataFrame(\n",
    "    [\n",
    "        (0, 22.0, 0.5, Vectors.dense([1.0, 20.0, 0.7]), 0.0),\n",
    "        (1, 15.0, 0.3, Vectors.dense([2.0, 30.0, 0.2]), 1.0),\n",
    "        (2, 25.0, 0.34, Vectors.dense([2.0, 25.0, 0.3]), 1.0),\n",
    "        (3, 19.0, 0.55, Vectors.dense([1.0, 50.0, 0.4]), 0.0),\n",
    "        (4, 11.0, 0.39, Vectors.dense([4.0, 20.0, 0.6]), 1.0),\n",
    "    ],\n",
    "    [\"id\", \"sessionDuration\", \"bounceRate\", \"userMetrics\", \"conversion\"],\n",
    ")\n",
    "\n",
    "# Creamos un ensamblador con las nuevas columnas.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"sessionDuration\", \"bounceRate\", \"userMetrics\"], outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Aplicamos el ensamblador para combinar las columnas en una nueva columna de tipo vector.\n",
    "output = assembler.transform(dataset)\n",
    "print(\"Assembled sessionDuration, bounceRate, userMetrics into column 'features'\")\n",
    "output.select(\"features\", \"conversion\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65eb9be-5a5b-4269-935c-57c1c5632f0c",
   "metadata": {},
   "source": [
    "# ESTIMATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977659ee-67fe-46ea-9b14-76e529196649",
   "metadata": {},
   "source": [
    "## REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a18272-b2f8-4740-a61b-61f0ca5659ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_train, df_test = output.select(\n",
    "    \"features\", F.col(\"conversion\").alias(\"label\")\n",
    ").randomSplit([0.55, 0.45])\n",
    "\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "trainedModel = lr.fit(df_train)\n",
    "\n",
    "# Uso del modelo ajustado como un transformador para generar predicciones.\n",
    "predictions = trainedModel.transform(df_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782a25d-b765-4a96-842a-569d11134f0d",
   "metadata": {},
   "source": [
    "## CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc4f70-038f-4111-8137-aefe072f34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "trainedModel = lr.fit(df_train)\n",
    "\n",
    "# Uso del modelo ajustado como un transformador para generar predicciones.\n",
    "predictions = trainedModel.transform(df_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f110a3-4efe-425e-b90f-659c566134f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(trainedModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(trainedModel.interceptVector))\n",
    "\n",
    "trainingSummary = trainedModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\n",
    "    \"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "    % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e9389-b1f3-4803-aac6-fbe8017eadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in hadoop\n",
    "\n",
    "trainedModel.write().overwrite().save(\"hdfs://namenode:9000/models/lr_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdc925-44b9-41e6-b80b-ab7a492377d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e68ef-7fb0-4b8c-b4a7-0fe9bd838868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
